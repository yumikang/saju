#!/usr/bin/env npx tsx
// ETL Step 2: ë°ì´í„° ì •ê·œí™” (Normalize)
// ìˆ˜ì§‘ëœ ì›ì‹œ ë°ì´í„°ë¥¼ í‘œì¤€ í˜•íƒœë¡œ ì •ê·œí™”í•˜ê³  ê²€ì¦

import { join } from 'path';
import { 
  ETLConfig, 
  RawData,
  NormalizedData,
  ProcessedHanjaRecord,
  ProcessingResult 
} from './lib/etl-types';
import { createLogger } from './lib/etl-logger';
import { 
  readJsonFile,
  writeJsonFile, 
  createProcessingResult, 
  createETLError,
  processBatches
} from './lib/etl-utils';
import { 
  safeNormalizeToPrismaElement,
  safeNormalizeToPrismaYinYang,
  safeNormalizeToPrismaReviewStatus
} from '../../app/lib/hanja-normalize';
import { lookupHanjaElement, hasElementMapping } from './lib/hanja-element-lookup';

const STEP_NAME = '20_normalize';

/**
 * Gov ë°ì´í„° ê°ì§€ í•¨ìˆ˜
 */
function isGovData(record: any): boolean {
  return record.source === 'supreme-court' || record.source === 'government';
}

/**
 * ë³µìˆ˜ ì½ê¸° ë¶„í•  ì²˜ë¦¬
 */
function splitMultipleReadings(reading: string): { primary: string; alternatives: string[] } {
  if (!reading || typeof reading !== 'string') {
    return { primary: '', alternatives: [] };
  }

  const readings = reading.split(',').map(r => r.trim()).filter(r => r.length > 0);
  
  return {
    primary: readings[0] || '',
    alternatives: readings.slice(1)
  };
}

/**
 * Gov ë°ì´í„°ìš© ì˜¤í–‰ ë§¤í•‘ ì‹œë„
 */
function tryElementLookup(character: string, originalElement?: string): {
  element?: string;
  mappingSource: 'original' | 'lookup' | 'none';
  lookupAvailable: boolean;
} {
  const lookupAvailable = hasElementMapping(character);
  
  // ì›ë³¸ ë°ì´í„°ì— ì˜¤í–‰ì´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
  if (originalElement && originalElement.trim()) {
    return {
      element: originalElement.trim(),
      mappingSource: 'original',
      lookupAvailable
    };
  }
  
  // ë£©ì—… í…Œì´ë¸”ì—ì„œ ì°¾ê¸°
  const lookupElement = lookupHanjaElement(character);
  if (lookupElement) {
    return {
      element: lookupElement,
      mappingSource: 'lookup',
      lookupAvailable: true
    };
  }
  
  return {
    mappingSource: 'none',
    lookupAvailable
  };
}

// ê¸°ë³¸ ì„¤ì •
const config: ETLConfig = {
  inputDir: 'scripts/etl/data/raw',
  outputDir: 'scripts/etl/data/normalized',
  logLevel: 'info',
  batchSize: 100,
  errorHandling: 'continue',
  createBackup: true
};

/**
 * í•œì ë ˆì½”ë“œ ì •ê·œí™”
 */
function normalizeHanjaRecord(record: any, recordIndex: number): {
  normalized: ProcessedHanjaRecord | null;
  errors: any[];
} {
  const errors: any[] = [];
  const processingLog: string[] = [];

  try {
    // í•„ìˆ˜ í•„ë“œ ê²€ì¦
    if (!record.character || typeof record.character !== 'string') {
      errors.push(createETLError(
        'validation',
        'Missing or invalid character field',
        record,
        `record_${recordIndex}`,
        'character'
      ));
      return { normalized: null, errors };
    }

    // Gov ë°ì´í„° íŠ¹ë³„ ì²˜ë¦¬
    const isGov = isGovData(record);
    let primaryReading = record.reading?.trim() || undefined;
    let alternativeReadings: string[] = [];
    
    if (isGov && record.reading) {
      const readingSplit = splitMultipleReadings(record.reading);
      primaryReading = readingSplit.primary || undefined;
      alternativeReadings = readingSplit.alternatives;
      if (alternativeReadings.length > 0) {
        processingLog.push(`Gov data: split readings ${record.reading} â†’ primary: ${primaryReading}, alternatives: [${alternativeReadings.join(', ')}]`);
      }
    }

    // ì˜¤í–‰ ë§¤í•‘ ì‹œë„ (Gov ë°ì´í„°ì¸ ê²½ìš° ë£©ì—… í…Œì´ë¸” í™œìš©)
    let elementValue = record.element?.trim() || undefined;
    let elementMappingSource = 'original';
    
    if (isGov) {
      const elementLookup = tryElementLookup(record.character, record.element);
      elementValue = elementLookup.element;
      elementMappingSource = elementLookup.mappingSource;
      
      if (elementLookup.mappingSource === 'lookup') {
        processingLog.push(`Gov data: element mapped via lookup table ${record.character} â†’ ${elementValue}`);
      } else if (elementLookup.mappingSource === 'none' && elementLookup.lookupAvailable) {
        processingLog.push(`Gov data: no element mapping found for ${record.character} (lookup table has this character)`);
      } else if (elementLookup.mappingSource === 'none') {
        processingLog.push(`Gov data: no element mapping found for ${record.character} (not in lookup table)`);
      }
    }

    // ê¸°ë³¸ ì •ê·œí™”ëœ ë ˆì½”ë“œ ìƒì„±
    const normalized: ProcessedHanjaRecord = {
      character: record.character.trim(),
      meaning: record.meaning?.trim() || undefined,
      reading: primaryReading,
      strokes: record.strokes || undefined,
      element: elementValue,
      yinYang: record.yinYang?.trim() || undefined,
      source: record.source || 'unknown',
      confidenceScore: record.confidenceScore || 0.5,
      metadata: {
        ...record.metadata,
        ...(isGov && alternativeReadings.length > 0 && { alternativeReadings }),
        ...(isGov && { elementMappingSource }),
        ...(isGov && record.metadata?.hexCode && { hexCode: record.metadata.hexCode }),
        ...(isGov && record.metadata?.dictionaryInfo && { dictionaryInfo: record.metadata.dictionaryInfo })
      },
      validationStatus: 'ok',
      processingLog: processingLog
    };

    // ì˜¤í–‰ ì •ê·œí™” (elementValue ì‚¬ìš© - Gov ë°ì´í„°ì˜ ê²½ìš° ë£©ì—…ëœ ê°’ í¬í•¨)
    if (elementValue) {
      const elementResult = safeNormalizeToPrismaElement(elementValue);
      if (elementResult.success) {
        normalized.normalizedElement = elementResult.value!;
        const sourceInfo = isGov ? ` (source: ${elementMappingSource})` : '';
        processingLog.push(`Element normalized: ${elementValue} â†’ ${elementResult.value}${sourceInfo}`);
      } else {
        errors.push(createETLError(
          'validation',
          `Element normalization failed: ${elementResult.error}`,
          elementValue,
          `record_${recordIndex}`,
          'element'
        ));
        normalized.validationStatus = 'needs_review';
        processingLog.push(`Element normalization failed: ${elementResult.error}`);
      }
    }

    // ìŒì–‘ ì •ê·œí™” (ìˆëŠ” ê²½ìš°)
    if (record.yinYang) {
      const yinYangResult = safeNormalizeToPrismaYinYang(record.yinYang);
      if (yinYangResult.success) {
        normalized.normalizedYinYang = yinYangResult.value!;
        processingLog.push(`YinYang normalized: ${record.yinYang} â†’ ${yinYangResult.value}`);
      } else {
        errors.push(createETLError(
          'validation',
          `YinYang normalization failed: ${yinYangResult.error}`,
          record.yinYang,
          `record_${recordIndex}`,
          'yinYang'
        ));
        normalized.validationStatus = 'needs_review';
        processingLog.push(`YinYang normalization failed: ${yinYangResult.error}`);
      }
    }

    // íšìˆ˜ ê²€ì¦ ë° ì •ê·œí™”
    if (record.strokes !== undefined) {
      const strokes = parseInt(String(record.strokes));
      if (isNaN(strokes) || strokes < 1 || strokes > 50) {
        errors.push(createETLError(
          'validation',
          `Invalid strokes value: ${record.strokes}`,
          record.strokes,
          `record_${recordIndex}`,
          'strokes'
        ));
        normalized.validationStatus = 'needs_review';
        processingLog.push(`Invalid strokes: ${record.strokes}`);
      } else {
        normalized.strokes = strokes;
        processingLog.push(`Strokes validated: ${strokes}`);
      }
    }

    // ë¬¸ì ìœ íš¨ì„± ê²€ì¦
    if (!/[\u4e00-\u9fff]/.test(normalized.character)) {
      errors.push(createETLError(
        'validation',
        `Character is not valid CJK: ${normalized.character}`,
        normalized.character,
        `record_${recordIndex}`,
        'character'
      ));
      normalized.validationStatus = 'needs_review';
      processingLog.push(`Character validation warning: not CJK range`);
    }

    // ì‹ ë¢°ë„ ì ìˆ˜ ì •ê·œí™”
    if (normalized.confidenceScore < 0 || normalized.confidenceScore > 1) {
      normalized.confidenceScore = Math.max(0, Math.min(1, normalized.confidenceScore));
      processingLog.push(`Confidence score clamped to [0,1]: ${normalized.confidenceScore}`);
    }

    normalized.processingLog = processingLog;
    return { normalized, errors };

  } catch (error) {
    errors.push(createETLError(
      'processing',
      `Unexpected error during normalization: ${error instanceof Error ? error.message : String(error)}`,
      record,
      `record_${recordIndex}`,
      undefined,
      { error }
    ));
    return { normalized: null, errors };
  }
}

/**
 * ë°°ì¹˜ ì •ê·œí™” ì²˜ë¦¬
 */
async function normalizeBatch(
  records: any[], 
  batchIndex: number,
  logger: any
): Promise<{ normalized: ProcessedHanjaRecord[], errors: any[] }> {
  const normalized: ProcessedHanjaRecord[] = [];
  const errors: any[] = [];

  records.forEach((record, index) => {
    const globalIndex = batchIndex * config.batchSize + index;
    const result = normalizeHanjaRecord(record, globalIndex);
    
    if (result.normalized) {
      normalized.push(result.normalized);
    }
    errors.push(...result.errors);
  });

  logger.debug(`Batch ${batchIndex}: processed ${records.length} records, ${normalized.length} normalized, ${errors.length} errors`);
  
  return { normalized, errors };
}

/**
 * ì •ê·œí™” ë©”íŠ¸ë¦­ ê³„ì‚°
 */
function calculateNormalizationMetrics(
  totalRecords: number,
  normalizedRecords: ProcessedHanjaRecord[],
  errors: any[]
) {
  const fieldStats = {
    element: { attempted: 0, successful: 0, failed: 0 },
    yinYang: { attempted: 0, successful: 0, failed: 0 },
    strokes: { attempted: 0, successful: 0, failed: 0 },
    meaning: { attempted: 0, successful: 0, failed: 0 },
    reading: { attempted: 0, successful: 0, failed: 0 }
  };

  // ì„±ê³µí•œ ë ˆì½”ë“œì˜ í•„ë“œ í†µê³„
  normalizedRecords.forEach(record => {
    if (record.element) fieldStats.element.attempted++;
    if (record.normalizedElement) fieldStats.element.successful++;
    
    if (record.yinYang) fieldStats.yinYang.attempted++;
    if (record.normalizedYinYang) fieldStats.yinYang.successful++;
    
    if (record.strokes) fieldStats.strokes.attempted++;
    if (record.strokes && record.strokes > 0) fieldStats.strokes.successful++;
    
    if (record.meaning) fieldStats.meaning.attempted++;
    if (record.meaning && record.meaning.length > 0) fieldStats.meaning.successful++;
    
    if (record.reading) fieldStats.reading.attempted++;
    if (record.reading && record.reading.length > 0) fieldStats.reading.successful++;
  });

  // ì—ëŸ¬ í†µê³„ ë°˜ì˜
  errors.forEach(error => {
    if (error.field && fieldStats[error.field as keyof typeof fieldStats]) {
      fieldStats[error.field as keyof typeof fieldStats].failed++;
    }
  });

  return {
    totalRecords,
    normalizedSuccessfully: normalizedRecords.length,
    normalizationErrors: errors.length,
    fieldNormalizationStats: fieldStats
  };
}

/**
 * ë©”ì¸ ì •ê·œí™” í•¨ìˆ˜
 */
async function normalize(): Promise<ProcessingResult<NormalizedData>> {
  const logger = createLogger(config);
  const startTime = new Date();
  
  logger.startStep(STEP_NAME);

  try {
    // ì›ì‹œ ë°ì´í„° ë¡œë“œ (ê¸°ì¡´ + Gov ë°ì´í„°)
    const inputPath = join(config.inputDir, 'raw_data.json');
    const govInputPath = join(config.inputDir, 'gov-2025-08-20T06-58-47-164Z.json');
    
    logger.info(`Loading raw data from: ${inputPath}`);
    const rawData = await readJsonFile<RawData>(inputPath);
    logger.info(`Loaded ${rawData.records.length} existing raw records`);
    
    // Gov ë°ì´í„°ë„ ë¡œë“œ (ìˆëŠ” ê²½ìš°)
    let govRecords: any[] = [];
    try {
      logger.info(`Loading Gov data from: ${govInputPath}`);
      const govData = await readJsonFile<any>(govInputPath);
      govRecords = govData.records || govData;
      
      // Gov ë°ì´í„°ì— source í•„ë“œ ì¶”ê°€
      govRecords = govRecords.map(record => ({
        ...record,
        source: record.source || 'supreme-court',
        confidenceScore: record.confidenceScore || 0.8
      }));
      
      logger.info(`Loaded ${govRecords.length} Gov records`);
    } catch (govError) {
      logger.warn(`Could not load Gov data: ${govError instanceof Error ? govError.message : String(govError)}`);
    }
    
    // í†µí•© ë ˆì½”ë“œ ìƒì„±
    const allRecords = [...rawData.records, ...govRecords];
    logger.info(`Total records to process: ${allRecords.length} (existing: ${rawData.records.length}, gov: ${govRecords.length})`);
    
    // rawData ê°ì²´ë¥¼ í†µí•© ë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸
    const combinedRawData = {
      ...rawData,
      records: allRecords,
      metadata: {
        ...rawData.metadata,
        totalRecords: allRecords.length,
        sources: {
          existing: rawData.records.length,
          government: govRecords.length
        }
      }
    };

    // ë°°ì¹˜ë¡œ ì •ê·œí™” ì²˜ë¦¬
    logger.info(`Processing in batches of ${config.batchSize}`);
    
    const allNormalized: ProcessedHanjaRecord[] = [];
    const allErrors: any[] = [];

    const batchResults = await processBatches(
      combinedRawData.records,
      config.batchSize,
      async (batch, batchIndex) => {
        const result = await normalizeBatch(batch, batchIndex, logger);
        allNormalized.push(...result.normalized);
        allErrors.push(...result.errors);
        
        logger.updateProgress(
          (batchIndex + 1) * config.batchSize,
          combinedRawData.records.length,
          'Normalizing records'
        );
        
        return result.normalized;
      }
    );

    // ì •ê·œí™” ë©”íŠ¸ë¦­ ê³„ì‚°
    const normalizationMetrics = calculateNormalizationMetrics(
      combinedRawData.records.length,
      allNormalized,
      allErrors
    );

    // ì •ê·œí™”ëœ ë°ì´í„° ê°ì²´ ìƒì„±
    const normalizedData: NormalizedData = {
      records: allNormalized,
      normalizationMetrics
    };

    // ê²°ê³¼ ì €ì¥
    const outputPath = join(config.outputDir, 'normalized_data.json');
    await writeJsonFile(outputPath, normalizedData);

    // ì²˜ë¦¬ ê²°ê³¼ ìƒì„±
    const endTime = new Date();
    const result = createProcessingResult(
      normalizedData,
      allNormalized.length,
      allErrors,
      startTime,
      endTime
    );

    logger.endStep(STEP_NAME, result);
    logger.info(`Normalization completed. Output saved to: ${outputPath}`);
    logger.info(`Normalized: ${allNormalized.length}/${combinedRawData.records.length} records (existing: ${rawData.records.length}, gov: ${govRecords.length})`);
    logger.info('Field normalization stats:', normalizationMetrics.fieldNormalizationStats);
    
    // Gov ë°ì´í„° ì²˜ë¦¬ í†µê³„ ë¡œê·¸
    const govProcessed = allNormalized.filter(r => r.source === 'supreme-court' || r.source === 'government');
    const govWithAlternatives = govProcessed.filter(r => r.metadata?.alternativeReadings?.length > 0);
    const govWithLookupElement = govProcessed.filter(r => r.metadata?.elementMappingSource === 'lookup');
    
    if (govProcessed.length > 0) {
      logger.info(`Gov data processed: ${govProcessed.length} records`);
      logger.info(`  - With alternative readings: ${govWithAlternatives.length}`);
      logger.info(`  - Element from lookup table: ${govWithLookupElement.length}`);
    }

    return result;

  } catch (error) {
    const endTime = new Date();
    const errorObj = createETLError(
      'system',
      `Normalization failed: ${error instanceof Error ? error.message : String(error)}`,
      undefined,
      undefined,
      undefined,
      { error }
    );

    const result = createProcessingResult(
      null,
      0,
      [errorObj],
      startTime,
      endTime
    );

    logger.endStep(STEP_NAME, result);
    logger.error('Normalization failed', { error });
    throw error;
  }
}

// CLI ì‹¤í–‰ ì§€ì›
if (import.meta.url === `file://${process.argv[1]}`) {
  normalize()
    .then(result => {
      console.log('âœ… Normalization completed successfully');
      console.log(`ğŸ“Š Processed: ${result.processedCount} records`);
      console.log(`âœ… Success: ${result.successCount} records`);
      console.log(`âŒ Errors: ${result.errorCount} errors`);
      console.log(`â±ï¸  Duration: ${result.metrics.processingTimeMs}ms`);
      
      if (result.data?.normalizationMetrics) {
        const metrics = result.data.normalizationMetrics;
        console.log('\nğŸ“ˆ Normalization Metrics:');
        Object.entries(metrics.fieldNormalizationStats).forEach(([field, stats]) => {
          if (stats.attempted > 0) {
            const successRate = Math.round((stats.successful / stats.attempted) * 100);
            console.log(`  ${field}: ${stats.successful}/${stats.attempted} (${successRate}%)`);
          }
        });
      }
      
      process.exit(0);
    })
    .catch(error => {
      console.error('âŒ Normalization failed:', error.message);
      process.exit(1);
    });
}

export { normalize };