#!/usr/bin/env npx tsx
// ETL Step 2: ë°ì´í„° ì •ê·œí™” (Normalize)
// ìˆ˜ì§‘ëœ ì›ì‹œ ë°ì´í„°ë¥¼ í‘œì¤€ í˜•íƒœë¡œ ì •ê·œí™”í•˜ê³  ê²€ì¦

import { join } from 'path';
import { 
  ETLConfig, 
  RawData,
  NormalizedData,
  ProcessedHanjaRecord,
  ProcessingResult 
} from './lib/etl-types';
import { createLogger } from './lib/etl-logger';
import { 
  readJsonFile,
  writeJsonFile, 
  createProcessingResult, 
  createETLError,
  processBatches
} from './lib/etl-utils';
import { 
  safeNormalizeToPrismaElement,
  safeNormalizeToPrismaYinYang,
  safeNormalizeToPrismaReviewStatus
} from '../../app/lib/hanja-normalize';

const STEP_NAME = '20_normalize';

// ê¸°ë³¸ ì„¤ì •
const config: ETLConfig = {
  inputDir: 'scripts/etl/data/raw',
  outputDir: 'scripts/etl/data/normalized',
  logLevel: 'info',
  batchSize: 100,
  errorHandling: 'continue',
  createBackup: true
};

/**
 * í•œì ë ˆì½”ë“œ ì •ê·œí™”
 */
function normalizeHanjaRecord(record: any, recordIndex: number): {
  normalized: ProcessedHanjaRecord | null;
  errors: any[];
} {
  const errors: any[] = [];
  const processingLog: string[] = [];

  try {
    // í•„ìˆ˜ í•„ë“œ ê²€ì¦
    if (!record.character || typeof record.character !== 'string') {
      errors.push(createETLError(
        'validation',
        'Missing or invalid character field',
        record,
        `record_${recordIndex}`,
        'character'
      ));
      return { normalized: null, errors };
    }

    // ê¸°ë³¸ ì •ê·œí™”ëœ ë ˆì½”ë“œ ìƒì„±
    const normalized: ProcessedHanjaRecord = {
      character: record.character.trim(),
      meaning: record.meaning?.trim() || undefined,
      reading: record.reading?.trim() || undefined,
      strokes: record.strokes || undefined,
      element: record.element?.trim() || undefined,
      yinYang: record.yinYang?.trim() || undefined,
      source: record.source || 'unknown',
      confidenceScore: record.confidenceScore || 0.5,
      metadata: record.metadata || {},
      validationStatus: 'ok',
      processingLog: processingLog
    };

    // ì˜¤í–‰ ì •ê·œí™”
    if (record.element) {
      const elementResult = safeNormalizeToPrismaElement(record.element);
      if (elementResult.success) {
        normalized.normalizedElement = elementResult.value!;
        processingLog.push(`Element normalized: ${record.element} â†’ ${elementResult.value}`);
      } else {
        errors.push(createETLError(
          'validation',
          `Element normalization failed: ${elementResult.error}`,
          record.element,
          `record_${recordIndex}`,
          'element'
        ));
        normalized.validationStatus = 'needs_review';
        processingLog.push(`Element normalization failed: ${elementResult.error}`);
      }
    }

    // ìŒì–‘ ì •ê·œí™” (ìˆëŠ” ê²½ìš°)
    if (record.yinYang) {
      const yinYangResult = safeNormalizeToPrismaYinYang(record.yinYang);
      if (yinYangResult.success) {
        normalized.normalizedYinYang = yinYangResult.value!;
        processingLog.push(`YinYang normalized: ${record.yinYang} â†’ ${yinYangResult.value}`);
      } else {
        errors.push(createETLError(
          'validation',
          `YinYang normalization failed: ${yinYangResult.error}`,
          record.yinYang,
          `record_${recordIndex}`,
          'yinYang'
        ));
        normalized.validationStatus = 'needs_review';
        processingLog.push(`YinYang normalization failed: ${yinYangResult.error}`);
      }
    }

    // íšìˆ˜ ê²€ì¦ ë° ì •ê·œí™”
    if (record.strokes !== undefined) {
      const strokes = parseInt(String(record.strokes));
      if (isNaN(strokes) || strokes < 1 || strokes > 50) {
        errors.push(createETLError(
          'validation',
          `Invalid strokes value: ${record.strokes}`,
          record.strokes,
          `record_${recordIndex}`,
          'strokes'
        ));
        normalized.validationStatus = 'needs_review';
        processingLog.push(`Invalid strokes: ${record.strokes}`);
      } else {
        normalized.strokes = strokes;
        processingLog.push(`Strokes validated: ${strokes}`);
      }
    }

    // ë¬¸ì ìœ íš¨ì„± ê²€ì¦
    if (!/[\u4e00-\u9fff]/.test(normalized.character)) {
      errors.push(createETLError(
        'validation',
        `Character is not valid CJK: ${normalized.character}`,
        normalized.character,
        `record_${recordIndex}`,
        'character'
      ));
      normalized.validationStatus = 'needs_review';
      processingLog.push(`Character validation warning: not CJK range`);
    }

    // ì‹ ë¢°ë„ ì ìˆ˜ ì •ê·œí™”
    if (normalized.confidenceScore < 0 || normalized.confidenceScore > 1) {
      normalized.confidenceScore = Math.max(0, Math.min(1, normalized.confidenceScore));
      processingLog.push(`Confidence score clamped to [0,1]: ${normalized.confidenceScore}`);
    }

    normalized.processingLog = processingLog;
    return { normalized, errors };

  } catch (error) {
    errors.push(createETLError(
      'processing',
      `Unexpected error during normalization: ${error instanceof Error ? error.message : String(error)}`,
      record,
      `record_${recordIndex}`,
      undefined,
      { error }
    ));
    return { normalized: null, errors };
  }
}

/**
 * ë°°ì¹˜ ì •ê·œí™” ì²˜ë¦¬
 */
async function normalizeBatch(
  records: any[], 
  batchIndex: number,
  logger: any
): Promise<{ normalized: ProcessedHanjaRecord[], errors: any[] }> {
  const normalized: ProcessedHanjaRecord[] = [];
  const errors: any[] = [];

  records.forEach((record, index) => {
    const globalIndex = batchIndex * config.batchSize + index;
    const result = normalizeHanjaRecord(record, globalIndex);
    
    if (result.normalized) {
      normalized.push(result.normalized);
    }
    errors.push(...result.errors);
  });

  logger.debug(`Batch ${batchIndex}: processed ${records.length} records, ${normalized.length} normalized, ${errors.length} errors`);
  
  return { normalized, errors };
}

/**
 * ì •ê·œí™” ë©”íŠ¸ë¦­ ê³„ì‚°
 */
function calculateNormalizationMetrics(
  totalRecords: number,
  normalizedRecords: ProcessedHanjaRecord[],
  errors: any[]
) {
  const fieldStats = {
    element: { attempted: 0, successful: 0, failed: 0 },
    yinYang: { attempted: 0, successful: 0, failed: 0 },
    strokes: { attempted: 0, successful: 0, failed: 0 },
    meaning: { attempted: 0, successful: 0, failed: 0 },
    reading: { attempted: 0, successful: 0, failed: 0 }
  };

  // ì„±ê³µí•œ ë ˆì½”ë“œì˜ í•„ë“œ í†µê³„
  normalizedRecords.forEach(record => {
    if (record.element) fieldStats.element.attempted++;
    if (record.normalizedElement) fieldStats.element.successful++;
    
    if (record.yinYang) fieldStats.yinYang.attempted++;
    if (record.normalizedYinYang) fieldStats.yinYang.successful++;
    
    if (record.strokes) fieldStats.strokes.attempted++;
    if (record.strokes && record.strokes > 0) fieldStats.strokes.successful++;
    
    if (record.meaning) fieldStats.meaning.attempted++;
    if (record.meaning && record.meaning.length > 0) fieldStats.meaning.successful++;
    
    if (record.reading) fieldStats.reading.attempted++;
    if (record.reading && record.reading.length > 0) fieldStats.reading.successful++;
  });

  // ì—ëŸ¬ í†µê³„ ë°˜ì˜
  errors.forEach(error => {
    if (error.field && fieldStats[error.field as keyof typeof fieldStats]) {
      fieldStats[error.field as keyof typeof fieldStats].failed++;
    }
  });

  return {
    totalRecords,
    normalizedSuccessfully: normalizedRecords.length,
    normalizationErrors: errors.length,
    fieldNormalizationStats: fieldStats
  };
}

/**
 * ë©”ì¸ ì •ê·œí™” í•¨ìˆ˜
 */
async function normalize(): Promise<ProcessingResult<NormalizedData>> {
  const logger = createLogger(config);
  const startTime = new Date();
  
  logger.startStep(STEP_NAME);

  try {
    // ì›ì‹œ ë°ì´í„° ë¡œë“œ
    const inputPath = join(config.inputDir, 'raw_data.json');
    logger.info(`Loading raw data from: ${inputPath}`);
    
    const rawData = await readJsonFile<RawData>(inputPath);
    logger.info(`Loaded ${rawData.records.length} raw records`);

    // ë°°ì¹˜ë¡œ ì •ê·œí™” ì²˜ë¦¬
    logger.info(`Processing in batches of ${config.batchSize}`);
    
    const allNormalized: ProcessedHanjaRecord[] = [];
    const allErrors: any[] = [];

    const batchResults = await processBatches(
      rawData.records,
      config.batchSize,
      async (batch, batchIndex) => {
        const result = await normalizeBatch(batch, batchIndex, logger);
        allNormalized.push(...result.normalized);
        allErrors.push(...result.errors);
        
        logger.updateProgress(
          (batchIndex + 1) * config.batchSize,
          rawData.records.length,
          'Normalizing records'
        );
        
        return result.normalized;
      }
    );

    // ì •ê·œí™” ë©”íŠ¸ë¦­ ê³„ì‚°
    const normalizationMetrics = calculateNormalizationMetrics(
      rawData.records.length,
      allNormalized,
      allErrors
    );

    // ì •ê·œí™”ëœ ë°ì´í„° ê°ì²´ ìƒì„±
    const normalizedData: NormalizedData = {
      records: allNormalized,
      normalizationMetrics
    };

    // ê²°ê³¼ ì €ì¥
    const outputPath = join(config.outputDir, 'normalized_data.json');
    await writeJsonFile(outputPath, normalizedData);

    // ì²˜ë¦¬ ê²°ê³¼ ìƒì„±
    const endTime = new Date();
    const result = createProcessingResult(
      normalizedData,
      allNormalized.length,
      allErrors,
      startTime,
      endTime
    );

    logger.endStep(STEP_NAME, result);
    logger.info(`Normalization completed. Output saved to: ${outputPath}`);
    logger.info(`Normalized: ${allNormalized.length}/${rawData.records.length} records`);
    logger.info('Field normalization stats:', normalizationMetrics.fieldNormalizationStats);

    return result;

  } catch (error) {
    const endTime = new Date();
    const errorObj = createETLError(
      'system',
      `Normalization failed: ${error instanceof Error ? error.message : String(error)}`,
      undefined,
      undefined,
      undefined,
      { error }
    );

    const result = createProcessingResult(
      null,
      0,
      [errorObj],
      startTime,
      endTime
    );

    logger.endStep(STEP_NAME, result);
    logger.error('Normalization failed', { error });
    throw error;
  }
}

// CLI ì‹¤í–‰ ì§€ì›
if (import.meta.url === `file://${process.argv[1]}`) {
  normalize()
    .then(result => {
      console.log('âœ… Normalization completed successfully');
      console.log(`ğŸ“Š Processed: ${result.processedCount} records`);
      console.log(`âœ… Success: ${result.successCount} records`);
      console.log(`âŒ Errors: ${result.errorCount} errors`);
      console.log(`â±ï¸  Duration: ${result.metrics.processingTimeMs}ms`);
      
      if (result.data?.normalizationMetrics) {
        const metrics = result.data.normalizationMetrics;
        console.log('\nğŸ“ˆ Normalization Metrics:');
        Object.entries(metrics.fieldNormalizationStats).forEach(([field, stats]) => {
          if (stats.attempted > 0) {
            const successRate = Math.round((stats.successful / stats.attempted) * 100);
            console.log(`  ${field}: ${stats.successful}/${stats.attempted} (${successRate}%)`);
          }
        });
      }
      
      process.exit(0);
    })
    .catch(error => {
      console.error('âŒ Normalization failed:', error.message);
      process.exit(1);
    });
}

export { normalize };